{
 "cells": [
  {
   "cell_type": "raw",
   "id": "23173cc4",
   "metadata": {
    "id": "Rk1FKlNw6iud",
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac5c3e47",
   "metadata": {
    "id": "qePUzMOm7j5b",
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe38a681",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "!pip install textrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5326cf1d",
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1642760787017,
     "user": {
      "displayName": "Алтухов Никита",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16291664936428813404"
     },
     "user_tz": -180
    },
    "id": "88bd3cc4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from transformers import T5Model, T5Tokenizer\n",
    "\n",
    "from textrl import TextRLEnv, TextRLActor\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bd3cc4",
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1642760787017,
     "user": {
      "displayName": "Алтухов Никита",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16291664936428813404"
     },
     "user_tz": -180
    },
    "id": "88bd3cc4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/ruT5-base')  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('sberbank-ai/ruT5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1b594",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence_sim_model = SentenceTransformer('models/DeepPavlov_rubert-base-cased-sentence/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c710f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check:\n",
    "https://github.com/voidful/TextRL/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8226d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_text, predicted_list, finish): # predicted will be the list of predicted token\n",
    "        if \"[UNK]\" in predicted_list:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1021056d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184,
     "referenced_widgets": [
      "3e988008196c421baee191b08f6435b8",
      "9b971deac1434209a471b50c57a9a19c",
      "3f5f9d05f4c746289dc5d82c05519bf4",
      "ea06082ad47447a9b5132f311e118e17",
      "426ba4f35a91412bb1f7aafa4b736438",
      "81b08b9072c34e238d4a39bbaee9b470",
      "3067791fc75e43beb0746ca4822c101c",
      "7e53ca6be6f44e4fafd8ca5b4eb3b5a7",
      "431efc8ae00f44b584316192d4a1dc68",
      "d64e714564dc43a9b6f3b8a05407f3de",
      "d26d0ec9a41843d285aae64b87791bea",
      "384873c21ee646f5835ee10d9bf744c1",
      "104b13d20bdc438790e84373f4577b19",
      "1fb9778456b94afe828d87dfc034409d",
      "fbe0e4396b214eabb213baaf33f02799",
      "077ff3935a734b9489e81107dc68b19e",
      "e1d7347292544437a3b691a70b8cd31a",
      "e6389464927442a7961477581c1fda47",
      "3449419885f649ae99db6075ba7de7a3",
      "951a99ed06c5486580f5ffa0204e23f9",
      "fdcf4e6ddb1641c0bc2e5aa2c2f290d2",
      "593413bfbe794d5395e9c2764e352b18",
      "aec0920756ae435fa7b06264ade9df8c",
      "d3e77a991f4446698d3b20855f5cc8ff",
      "1f6e6950f86a48f5a2146b3e21851adc",
      "1a38223df58649c099728ff7b02268f2",
      "17bfce20228048948600bf203d9aa0a4",
      "b5110dc390f5475381f02eca6d96d6d0",
      "2df13cc9a50047a6abb6bce92c0604ab",
      "68d4c994057146988e28bb6610986e2a",
      "4a573ecd9e4645fbb92e860faf923961",
      "151678ce1a5b47319287d1de12f3ff8a",
      "4ec57988bcd24900a61a2686b69c32dd"
     ]
    },
    "executionInfo": {
     "elapsed": 23834,
     "status": "ok",
     "timestamp": 1642760843748,
     "user": {
      "displayName": "Алтухов Никита",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16291664936428813404"
     },
     "user_tz": -180
    },
    "id": "1021056d",
    "outputId": "36a8002e-aa46-4e2d-9acf-23b5a1f3f2be",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sberbank-ai/ruT5-base were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('sberbank-ai/ruT5-base')\n",
    "t5 = T5Model.from_pretrained('sberbank-ai/ruT5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fFVSC5W0BY41",
   "metadata": {
    "id": "fFVSC5W0BY41",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Ie9Lh41lqIgK",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1642761350254,
     "user": {
      "displayName": "Алтухов Никита",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16291664936428813404"
     },
     "user_tz": -180
    },
    "id": "Ie9Lh41lqIgK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class JokeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, sentence_length=150):\n",
    "        super().__init__()\n",
    "        self.dataset = df \\\n",
    "          .sort_values(['setup', 'punch']) \\\n",
    "          .reset_index()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentence_length = sentence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def tokenize_input(self, input_tests):\n",
    "        encode = self.tokenizer(\n",
    "            input_tests, \n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.sentence_length,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        word_ids = encode.input_ids[0]\n",
    "        masks = (encode.special_tokens_mask[0] == 0).to(torch.int8)\n",
    "\n",
    "        return word_ids, masks\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        setup_text = self.dataset.setup[idx]\n",
    "        punch_text = self.dataset.punch[idx]\n",
    "\n",
    "        setup_encode_ids, setup_encode_mask = self.tokenize_input(setup_text)\n",
    "        punch_encode_ids, punch_encode_mask = self.tokenize_input(punch_text)\n",
    "\n",
    "        if 'mark' in self.dataset.columns:\n",
    "            target = self.dataset.mark[idx]\n",
    "            return (setup_encode_ids, \n",
    "                  setup_encode_mask, \n",
    "                  punch_encode_ids, \n",
    "                  punch_encode_mask,\n",
    "                  target)\n",
    "        else:\n",
    "            return (setup_encode_ids, \n",
    "                  setup_encode_mask, \n",
    "                  punch_encode_ids, \n",
    "                  punch_encode_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796ff63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}